\chapter{Monads}

\marginnote{A monad is just a monoid in the category of endoburritos.}
Monads are widely used for structuring effectful computation in functional
programs.  For example, we can have a small functional programming language with
a monadic type-former $\plkw{T}$:

\begin{gather}
  \begin{aligned}
   A,B ::=& \plkw{Unit}
     \mid A \pltimes B
     \mid A \plto B 
     \mid \plkw{T}~A
  \\
  M,N ::=& \plunit{}
      \mid \plpair{M}{N}
      \mid \plfst{M}
      \mid \plsnd{M}
      \mid \pllam{x}{M}
      \mid \plapp{M}{N}
      \mid x \\
      & \mid \plpure{M} 
      \mid x \leftarrow M; N
  \end{aligned}
\end{gather}

The syntax $\plpure{M}$ \emph{lifts} a pure computation into a monadic
one, and the syntax $x \leftarrow M; N$ is a \emph{monadic bind}
that enables computation inside the monad. The way that these 
syntactic forms are used is best understood via their typing judgments:

\begin{mathpar}
    \inferrule{\Gamma \vdash M : A}{\Gamma \vdash \plpure{M} : \plkw{T}~A}
    \qquad
    \inferrule{\Gamma \vdash M : \plkw{T}~A
    \qquad
    \Gamma, x : A \vdash N : \plkw{T}~B
    }{\Gamma \vdash x \leftarrow M; N : \plkw{T}~B}
\end{mathpar}



If you've programmed in Haskell, you're quite familiar with 
examples of monads. A simple example is the \texttt{Maybe}
monad, which lets you program with values that can 
be either \texttt{Nothing} or \texttt{Just} a value. 
This makes it a convenient pattern for implementing 
and sequencing partial functions, as the following Haskell code 
illustrates:

\begin{lstlisting}
divide :: Double -> Double -> Maybe Double
divide a 0 = Nothing
divide a b = Just $ a / b

my_computation :: Double -> Maybe Double
my_computation x = do
  div1 <- divide 10 x;
  div2 <- divide 20 x;
  divide div1 div2
\end{lstlisting}

As usual for this book let's consider now the denotational semantics of monads.
Let's start with the type former $\plkw{T}~M$.
We typically think of the interpretation of types as ``a space of values that
behave like a type'', where we use universal properties to characterize what it
means to behave like a type. A monad is a new and exciting creature when viewed from 
this lens: it \emph{takes in a type $A$} (so it is higher-order), and it 
produces a \emph{new type} $\dbracket{\plkw{T}~A}$  that has $A$ living inside of it.
This feels very functorial. We can couple this intuition with the requirement 
that denotational semantics be defined compositionally, and we can arrive at the 
conclusion that \emph{$\dbracket{\plkw{T}}$ is a functor}:
\begin{align}
    \dbracket{\plkw{T}~A} = \dbracket{\plkw{T}}(\dbracket{A})
\end{align}

Concretely, suppose we are interpreting our small higher-order language in 
some Cartesian-closed category $\calC$. Then, $\dbracket{\plkw{T}}$ 
is an \emph{endofunctor} $\dbracket{\plkw{T}} : \calC \to \calC$, a particular 
kind of functor from a category into itself. One way of understanding what 
$T$ is is that it maps elements to \emph{generalized elements} that are 
imbued with the additional structure of the monad.
\marginnote{\citep{asilis2020probability} has a very nice discussion of 
this motivation of monads as ``generalized elements of a category''.}

As usual we don't know what kind of properties the functor
$\dbracket{\plkw{T}~A}$ must have yet; to see those, we'll need to
reverse-engineer them from how monads are used. Let's start by 
examining \texttt{pure}. By our usual translation of typing judgments 
into morphisms, we can conclude that 
$\dbracket{\Gamma \vdash \plpure{M} : \plkw{T}~A}$ 
must have type $\dbracket{\Gamma} \to \dbracket{\plkw{T}}(\dbracket{A})$.
We need to build this morphism.
We know how to get close to it: 
$\dbracket{M : A}$ has type $\dbracket{\Gamma} \to \dbracket{A}$.
But, we need an extra morphism to get from $A$ to $\plkw{T}~A$: 
this is called the \emph{unit} of the monad at $\dbracket{A}$, and will be denoted 
$\eta_{\dbracket{A}}$:
\begin{align*}
    \dbracket{\Gamma \vdash \plkw{pure}~M :\plkw{T}~A} = 
    \dbracket{\Gamma} \mor{\dbracket{M}} \dbracket{A} \mor{\eta_{\dbracket{A}}} \dbracket{\plkw{T}}(\dbracket{A})
\end{align*}

In Haskell, $\eta$ is called \texttt{pure} or \texttt{return}. 
Notably, in Haskell, \texttt{pure} is a polymorphic function of 
type \texttt{a -> m a} for some monad \texttt{m} and type 
parameter \texttt{a}. This is a polymorphic function, 
so it makes sense to think of $\eta$ as a \emph{natural transformation}
$\eta : \id_\calC \Rightarrow T$.

\begin{lstlisting}
class Functor m => Monad m where
  return :: alpha -> m alpha
  join :: m (m alpha) -> m alpha
\end{lstlisting}

Interpreting bind:

 \begin{align*}
    \dbracket{\inferrule{\Gamma \vdash M : \plkw{T}~A \and 
    \Gamma, x : A \vdash N : \plkw{T}~B
    }{\Gamma \vdash x \leftarrow M; N : \plkw{T}~B}}
    &: \dbracket{\Gamma} \to \dbracket{\plkw{T}}(\dbracket{B}) \\ 
    = \dbracket{\Gamma} &\mor{\langle \id, \dbracket{M} \rangle} \dbracket{\Gamma} \times \dbracket{\plkw{T}}(\dbracket{A}) \\
    &\mor{\text{strength}} \dbracket{T}(\dbracket{\Gamma} \times \dbracket{A}) \\ 
    &\mor{\dbracket{\plkw{T}}(\dbracket{N})} \dbracket{\plkw{T}} \Big( \dbracket{\plkw{T}}(\dbracket{B}) \Big) \\
    &\mor{\mu} \dbracket{\plkw{T}}(\dbracket{B})
\end{align*}

% \marginnote{\url{http://blog.sigfpe.com/2023/08/what-does-it-mean-for-monad-to-be-strong.html}}
% \begin{lstlisting}
% strength :: Monad m => (x, m y) -> m (x, y)
% strength (x, my) = do
%   y <- my
%   return (x, y)
% \end{lstlisting}

\section{What's the problem?}
\begin{quote}
    ``A monad is just a monoid in the category of endofunctors, what's the 
    problem?''

    \emph{-- Phil Wadler}
\end{quote}

We've seen how a monad consists of (1) an endofunctor $T :
\calC \to \calC$; (2) a \emph{unit} natural transformation $\eta : \id_\calC \Rightarrow T$
(3) a \emph{multiplication (or join)} natural transformation $\mu : T^2 \Rightarrow T$.
As usual, these special morphisms must satisfy certain laws in order to 
behave coherently. 
In particular, these two natural transformations need to satisfy natural \emph{monoid laws}.
Recall the definition of a monoid:
\begin{definition}[Monoid]
    A \emph{monoid} is a triple $(X, \bullet, e)$ where $X$ is a set, $\bullet$ is a 
    \emph{multiplication operator} $\bullet : X \times X \to X$,
    and $e \in X$ is a distinguished \emph{unit element} satisfying:
    (1) \emph{associativity}: for any $a, b, c \in X$ 
    it is the case that $a \bullet (b \bullet c) = (a \bullet b) \bullet c$ 
    and (2) unitality: for any $a \in X$ it is the case that $a \bullet e = e \bullet a = a$.
\end{definition}

A monad will satisfy categorical analogs of the monoid laws: the unit natural trasnformation $\eta$ 
must behave like a monoidal unit, and the multiplication natural transformation $\mu$ 
must behave like a monoidal product.
Let's examine associativity first.
This requirement can be captured by the following commutive square:

\begin{equation}
   % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRABUA9AZhAF9S6TLnyEUARnJVajFmy4AmfoJAZseAkTLjp9Zq0QdOSgUPWiikndT1zD7ftJhQA5vCKgAZgCcIAWyQyEBwIJEkQBiwwAxAoCCYAIwZWagALGDooJDAmBgZqHDosBjZIaJAbWRj2AB0avyYAAmUvXwDEIJCkBWpI8sM4xOSKkHTM7Nz84KKSwzKUmX02OobGh1MQH38wgtDEbl6omMGkhbGsxBy8gpnSggXbGJWmFs227t2kA4ijthPhtIZC5XKaFYp3cqVJaGZ6OPhAA
\begin{tikzcd}
    T^3 \arrow[r, "T\mu ", Rightarrow] \arrow[d, "\mu T", Rightarrow] & T^2 \arrow[d, "\mu", Rightarrow] \\
    T^2 \arrow[r, "\mu", Rightarrow]                                  & T                               
    \end{tikzcd} 
\label{eq:monad-assoc}
\end{equation}

This square has some unfamiliar notation in it: the 
natural transformations $T \mu$ is given by composing 
the natural transformation $\mu$ with the functor $T$. Concretely,
the natural transformation $T \mu$ has components 
$(T \mu)_A : T^3(A) \to T^2(A)$ given by 
composing $T$ with each component of $\mu$, 
i.e. $(T \mu)_A = T \circ \mu_A$. 
The definition for $\mu T$ is analogous.

The next requirement on the monad natural transformations is that $\eta$ 
behaves like a monoidal unit. This is captured by the following commuting diagram:

\begin{equation}
 % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRABUQBfU9TXfIRQBGclVqMWbdgD0ATN14gM2PASJyx1es1aIOivqsFFRw8Tqn7OXcTCgBzeEVAAzAE4QAtkjIgcEEgAzNQMWGB6IFAQTABGDKzUABYwdFBIYEwMDNQ4dFgMbJARIKF0sTAMAAr8akIg7lgOSTilErpsADqdODAAHjjAWFBcAPo2Sh7eSJr+gYghIGEl+tFxCW0paRlZOf75hfrFie1WIN29A0Mj44YgUz6IonPBoeGRa-EnW+mImdm5A5FAgnSyRbpeJh3B6+XLzZ7LD4xL6bVK-f57PIFYElbSScGdGB5AAEEzcnkeswCSAR7zYnw2yTROwB+2xRxBbTB0mJ3SJdGJbQY5UqNWM6n0jWarVsXCAA
\begin{tikzcd}
    T \arrow[rd, "\text{id}_T"', Rightarrow] \arrow[r, "\eta T", Rightarrow] & T^2 \arrow[d, "\mu", Rightarrow] & T \arrow[ld, "\text{id}_T", Rightarrow] \arrow[l, "T \eta "', Rightarrow] \\
                                                                             & T                                &                                                                          
    \end{tikzcd}
    \label{eq:monad-unit}
\end{equation}

There are two faces of this diagram each capturing one of the unitality 
requirements. The left square asserts that $\mu \circ \eta T = \id_T$,
and the right square asserts that $\mu \circ T \eta = \id_T$; these 
equations correspond naturally to the monoid unitality law.
Together, these equations define a monad:

\begin{definition}[Monad]
    \sloppy
    Let $\calC$ be a category. A \emph{monad} on $\calC$ 
    is a triple $(T, \eta, \mu)$ where 
$T :
\calC \to \calC$ is an endofunctor,  $\eta : \id_\calC \Rightarrow T$
is the \emph{unit} natural transformation,
and  $\mu : T^2 \Rightarrow T$
is a \emph{multiplication (or join)} natural transformation,
satisfying the associativity law in \cref{eq:monad-assoc}
and unit law in \cref{eq:monad-unit}.
\end{definition}


\section{Examples of monads}


\subsection{Maybe monad}
The \emph{maybe monad} is often the first example of a monad one 
encounters in Haskell.
Intuitively, the type $\plkw{Maybe}~A$ represents values that 
behave like $A$ extended with the option of being ``nothing''.

\begin{itemize}
    \item Let $F : \FinSet \to \FinSet$ be a functor:
    \begin{itemize}
        \item Action on objects: $A \mapsto A \uplus \{\star\}$
        \item Action on morphisms $ f : A \to B$: 
        \begin{align*}
            F(f) = a \mapsto \begin{cases}
                \mathsf{inl}~f(x) \quad& \text{if } a = \mathsf{inl}~x \\ 
                \mathsf{inr}~\star \quad& \text{if } a = \mathsf{inr}~\star
            \end{cases}
        \end{align*}
    \end{itemize}
    \item The unit $\eta : \id_\FinSet \Rightarrow F$ has components 
    that straightforwardly inject $A$ into $F(A)$:
    \begin{align*}
        \eta_A &: \id_\FinSet{} (A) \to F(A) \\
        &= x \mapsto \mathsf{inl}~x
    \end{align*}
    \item The multiplication $\mu : F^2 \rightarrow F$ merges the two 
    nested distinguished elements $\star$ into a single one and 
    flattens the nesting. 
\end{itemize}

\subsection{Powerset monad}
The \emph{powerset monad} is defined by

\begin{itemize}
    \item The \emph{powerset functor} $\wp : \FinSet \to \FinSet$ that sends 
    each finite set $A$ to the set of all subsets $\{A_i \mid A_i \subseteq A\}$
    is a monad.
    \item The unit $\eta : \id_\FinSet \Rightarrow \wp$ has components that 
    map sets to the singleton set containing them:
    \begin{align*}
        \eta_A &: A \to \wp(A) \\ 
        &= \{A\}
    \end{align*}
    \item The multiplication $\mu : \wp^2 \Rightarrow \wp$ 
    has components that ``unfold the double powerset'':
    \begin{align*}
        \mu_A &: \wp(\wp(A)) \Rightarrow \wp(A) \\
        &= \mathcal{S} \mapsto \bigcup_{A \in \mathcal{S}} A
    \end{align*}
\end{itemize}

\section{Monads from adjunctions}
A surprising fact: all adjunctions form a monad, and all monads 
come from an adjunction pair!

Let's see first how every adjunction forms a monad:

\begin{proposition}
    Consider functors $F : \calC \to \calD$ and $G : \calD \to \calC$ 
    where $F \dashv G$. Then, there is a unit to the 
    adjunction $\eta : \id_C \Rightarrow G \circ F$ 
    and co-unit $\nu : F \circ G \Rightarrow \id_D$.
    Then, there is a monad $(T, \eta, \mu)$:
    \begin{itemize}[noitemsep]
        \item Endofunctor $T$ given by the roundtrip $T = G \circ F$
        \item Unit given by the unit of the adjunction
        \item Multiplication $\mu : G \circ F \circ G \circ F \Rightarrow G \circ F$
        given by $\mu = G \circ \epsilon \circ F$.
    \end{itemize}

\end{proposition}

\subsection{Maybe monad from a free/forgetful adjunction}
\begin{itemize}
    \item Consider the categories $\FinSet$ and $\FinSet^*$.
    \item There is a functor $\mathsf{forget} : \FinSet^* \to \FinSet$ 
    called the \emph{forgetful functor} that ``forgets about the distinguished element''. 
    \item There is a functor $\mathsf{free} : \FinSet \to \FinSet^*$ that adds on 
    a distinguished element
    \item There is an adjunction $\mathsf{free} \dashv \mathsf{forgetful}$.
    \item The round trip $\mathsf{free} \circ \mathsf{forgetful}$ is exactly 
    the monad $F$ we built earlier for the maybe monad.

\end{itemize}

\subsection{List monad}

\begin{itemize}
    \item List monad: Free/forgetful adjunction between sets and monoids.
    Unit is singleton list construction; join is concatenation.
\end{itemize}
Example: the free $\dashv$ forgetful adjunction between 
pointed sets and ordinary sets is the \texttt{Maybe} monad.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Modeling effects with syntax}
Monads have found extensive application in computer science and langauge ideas 
for dealing with effects. The previous chapter showed how to interpret 
a monadic type, but it was not exactly clear how this captures the notion 
of an \emph{effectful} computation. Here our aim is to make this clear by 
elucidating the connection between a monad and its
\emph{Klesli category}, which can be thought of as a syntactic representation 
of the effects being modeled. For any particular monad $T$ on a category 
$\calC$, the monad will come about as an adjunction between $\calC$ 
and its Klesili category.

We can start by characterizing effects using tiny languages that capture 
only the effectful fragments of computation. For example, we can 
represent the computations taking place under the finite probability monad $\plkw{Dist}$
using the following tiny grammar:

\newcommand\plifflip[3]{\plkw{if}~\plflip{}(#1)~{#2}~{#3}}
\begin{align*}
    e_\plkw{Dist} ::= \plkw{pure}(v) \mid \plifflip{p}{e_1}{e_2}
\end{align*}

The syntax is extremely pared down: it does not have any features at all 
except for the ability to refer to values $v$, or 
branch on a random Boolean that is true with probability $p$.
The set of all terms that can be formed out of this grammar is parameterized by the 
collection of values $v$: for each set of values $\calV$ we denote the set of all terms 
from $e_\plkw{Dist}$ using values $\calV$ as $\mathsf{Exp}_\plkw{Dist}(\calV)$.

As usual, given a language it is useful to characterize its equivalences. This is a 
design question: you, as the designer of the effect, must decide which effectful 
programs ought to behave the same. Some equations are quite natural from 
this perspective:
\begin{mathpar}
    \inferrule{~}{\plifflip{p}{e}{e} \equiv e}~(\textsc{Drop})
    \and
    \inferrule{~}{\plifflip{p}{e_1}{e_2} \equiv \plifflip{1-p}{e_2}{e_1}}~(\textsc{Swap})
    \and
    \inferrule{~}{\plkw{if}~\plflip{}(1)~e_1~e_2 \equiv e_1}~(\textsc{Then})
    \and
    \inferrule{~}{\plkw{if}~\plflip{}(0)~e_1~e_2 \equiv e_2}~(\textsc{Else})
\end{mathpar}
The above equations capture natural reasoning principles.
But, is this \emph{all} the necessary equations that characterize? Here is an example 
of two tiny effectful programs that ought to be equivalent but aren't yet:
\begin{align*}
  \plifflip{1/2}{(\plifflip{1/3}{(\plkw{pure}~\top)}{(\plkw{pure}~\bot)})}{(\plkw{pure}~\bot)}
  \quad\stackrel?\equiv\quad
  \plifflip{1/6}{(\plkw{pure}~\top)}{(\plkw{pure}~\bot)}
\end{align*}

This motivates one more equation that captures all the equivalences for this effect:
\begin{mathpar}
  \inferrule
    {p_1 + p_2 + p_3 = 1 \\ p_{12} = p_1 + p_2 \\ p_{23} = p_2 + p_3}
    {\plkw{if}~\plflip{}(p_1+p_2)~(\plkw{if}~\plflip{}(p_1/p_{12})~e_1~e_2)~e_3 \equiv
     \plkw{if}~\plflip{}(p_1)~e_1~(\plkw{if}~\plflip{}(p_2/p_{23})~e_2~e_3)}~\textsc{(Assoc)}
\end{mathpar}

Now we have a tiny language that captures \emph{only} the effect of allocating 
and branching on random quantities. Using this tiny language, we can bolt on sampling
as a monad in the category of sets $\Set$.
Recall that the set $\mathsf{Exp}_\plkw{Dist}(\calV)$ of probabilistic computations
with values in \(\calV\) is parameterized by a set \(\calV\).
This can be used to define an endofunctor \(D : \Set \to \Set\):
\begin{align*}
  &D : \Set \to \Set \\
  &D(\calV) = \mathsf{Exp}_{\plkw{Dist}}(\calV) /_\equiv \\
  &D(f : \calV \to \calV') = e \mapsto e[f(v)/v]
\end{align*}
The action of this functor on morphisms sends a function \(f\)
to the function that uses \(f\) to substitute each value \(v\) in a given computation \(e\)
with \(f(v)\).

This endofunctor \(D\) forms a monad. The unit \(\eta\) is defined by
the coercion from values to computations:
\begin{align*}
  &\eta_{\calV} : \calV \to D(\calV) \\
  &\eta_{\calV}(v) = \plkw{pure}(v)
\end{align*}
The multiplication is defined by \emph{substitution}:
given a computation \(e\) that produces computations,
the multiplication \(\mu(e)\) is ``flattening'' of the syntax tree of \(e\):
\begin{align*}
  &\mu_{\calV} : D(D(\calV)) \to D(\calV) \\
  &\mu_{\calV}(\plkw{pure}(v)) = v \\
  &\mu_{\calV}(\plifflip{p}{e_1}{e_2}) = \plifflip{p}{\mu_{\calV}(e_1)}{\mu_{\calV}(e_2)} \\
\end{align*}
Note in the first case that the ``value'' \(v\) is an element of \(D(\calV)\).
Thinking of computations as abstract syntax trees, this multiplication operation
flattens a tree of trees into an ordinary tree.
One can check that the monad laws are satisfied;
they correspond to properties one might expect to hold of tree flattening.

The finite
probability distribution monad $\calD : \Set \to \Set$ sends sets $X$ to 
the set of finitely-supported functions $\mu : X \to [0,1]$ such that 
$\sum_{x \in X} \mu(x) = 1$.

As more convenient notation, we can describe a probability distribution on 
$X$ as a \emph{formal series}: a distribution $\mu : X \to [0,1]$ 
can be written as an expression $c_1 [x_1] + \cdots + c_n [x_n]$ where 
$c_i \in [0,1]$ are real-valued numbers satisfying $\sum_i c_i = 1$, 
and each $[x_i]$ is a \emph{formal parameter} (i.e., a variable).
There is a natural equivalence relation on formal series given by 
combining the coefficients of formal parameters:
\begin{align*}
    c_1 [x_1] + \cdots + c_i [x_i] + c_i' [x_i] + \cdots c_n [x_n]
    \equiv
    c_1 [x_1] + \cdots + (c_i + c_i') [x_i] + \cdots c_n [x_n]
\end{align*}
The additional equations of formal series are the natural equivalences 
given by the commutativity and associativity of addition and multiplication.


Now we can give the unit and multiplication natural transformations for $\calD$:
\begin{itemize}
    \item The unit $\eta : \id_\Set \Rightarrow \calD$ has components $\eta_X : X \to \calD(X)$
    that place all the probability mass on a single point: $\eta_X(x) = 1[x]$.
    \item Multiplication $\mu : \calD^2 \Rightarrow \calD$ merges the probability 
    distributions in the following way: 
    \begin{align*}
        \mu_X &: \calD\calD(X) \to \calD(X) \\
        &= (c_1[c_{11}[x_1] + \cdots + c_{n1}x[n]] + \cdots + c_n[c_{1n}[x_1] + \cdots + c_{nn}x[n]]) \\
        &\quad \mapsto
        (c_1(c_{11}[x_1] + \cdots + c_{n1}x[n]) + \cdots + c_n(c_{1n}[x_1] + \cdots + c_{nn}x[n]))
    \end{align*}
\end{itemize}

\begin{proposition}
  The monads \(D\) and \(\calD\) are isomorphic;
  that is, there is a natural isomorphism \(D \cong \calD\)
  that commutes with the unit and multiplication operations of \(D\) and \(\calD\) respectively.
\end{proposition}

Outline:
\begin{itemize}
    \item From what just happened to ``Kleisli category is syntactic description of a monad''. \begin{itemize}
      \item Taking stock of what happened with \(D\) and \(\calD\): starting from a syntactic
        description of probability, we recovered finitely-supported PMFs.
      \item Plotkin+Power's idea, inspired by Moggi's proposal to use monads:
        this is a recipe for modelling effects more generally:
        start from a syntactic description, add equations one expects should hold,
        and try to see what mathematical objects come out (c.f. algebraic effects)
      \item Examples: \begin{itemize}
        \item Failure: \(e ::= v \mid \plkw{fail}\). This recovers the Maybe monad.
        \item Nondeterminism: \(e ::= v \mid \plkw{amb}(e_1,e_2)\). This recovers the finite nonempty powerset monad.
        \item Logging: \(e ::= v \mid \plkw{log}(s); e\) (where \(s\) is drawn from some set of strings).
          This recovers the writer monad.
        \item Global state (one Boolean): \(e ::= v \mid x \gets \plkw{get}_b; e(x) \mid \plkw{put}_b; e\).
          This recovers the state monad, if you work hard to find the right equations~\cite{plotkin2002notions}.
        \end{itemize}
      \end{itemize}
    \item This approach of starting from syntax is essentially universal algebra.
      One nice consequence is that we can use results from universal algebra to study effects.
      We look at one example now: the idea of a Kleisli category of a monad. \begin{itemize}
      \item Definition of Kleisli category. Morphisms \(\calV \to T{\mathcal W}\) are like substitutions,
        showing how to transform each value \(\calV\) into a term \(T{\mathcal W}\).
      \item Example: for Dist, Kleisli morphisms are transition matrices.
        In the continuous case, Kleisli morphisms are Markov kernels.
      \item Example: for Maybe, Kleisli morphisms are partial functions.
      \end{itemize}
    \item Given a monad, find its Kleisli category and corresponding adjunction.
    \item The Kleisli monad models call-by-value computation.
      Universal algebra shows how to model call-by-name:
      Eilenberg-Moore, from the perspective of ``models of tiny language''.
\end{itemize}

% \marginnote{This chapter is heavily inspired by \citep{asilis2020probability}.}
% We saw in the previous chapter that every monad gives rise to an adjunction. 
% A natural question one might have, after seeing this, is: does \emph{every}
% monad comes from an adjunction? The answer is a very satisfying 
% \emph{yes}. In fact, there is more than one such adjunction that
% gives rise to every monad $T$ on a category $\calC$. Here are two important 
% categories that admit adjunctions that give rise to the monad $T$:
% \begin{itemize}
%     \item The \emph{Kleisli category} $\calC_T$, sometimes called the category of 
%     \emph{free $T$-algebras}, can be thought of as a syntactic characterization 
%     of a monad.
%     \item The \emph{Elienberg-Moore category} $\calC^T$, also called the \emph{category 
%     of $T$-algebras}, can be thought of a semantic characterization 
%     of a monad.
% \end{itemize}

% \section{The finite probability distribution monad}
% For this chapter we will introduce a particular monad as a running example: the
% \emph{finite probability distribution monad} $\calD$ on sets $\Set$. 
% Intuitively, the finite distribution monad $\calD$ sends objects $X$ 
% to the set of finitely-supported probability distributions one can 
% form on sets $X$. The finite
% probability distribution monad $\calD : \Set \to \Set$ sends sets $X$ to 
% the set of finitely-supported functions $\mu : X \to [0,1]$ such that 
% $\sum_{x \in X} \mu(x) = 1$.

% As more convenient notation, we can describe a probability distribution on 
% $X$ as a \emph{formal series}: a distribution $\mu : X \to [0,1]$ 
% can be written as an expression $c_1 [x_1] + \cdots + c_n [x_n]$ where 
% $c_i \in [0,1]$ are real-valued numbers satisfying $\sum_i c_i = 1$, 
% and each $[x_i]$ is a \emph{formal parameter} (i.e., a variable).
% There is a natural equivalence relation on formal series given by 
% combining the coefficients of formal parameters:
% \begin{align*}
%     c_1 [x_1] + \cdots + c_i [x_i] + c_i' [x_i] + \cdots c_n [x_n]
%     \equiv
%     c_1 [x_1] + \cdots + (c_i + c_i') [x_i] + \cdots c_n [x_n]
% \end{align*}
% The additional equations of formal series are the natural equivalences 
% given by the commutativity and associativity of addition and multiplication.


% Now we can give the unit and multiplication natural transformations for $\calD$:
% \begin{itemize}
%     \item The unit $\eta : \id_\Set \Rightarrow \calD$ has components $\eta_X : X \to \calD(X)$
%     that place all the probability mass on a single point: $\eta_X(x) = 1[x]$.
%     \item Multiplication $\mu : \calD^2 \Rightarrow \calD$ merges the probability 
%     distributions in the following way: 
%     \begin{align*}
%         \mu_X &: \calD\calD(X) \to \calD(X) \\
%         &= (c_1[c_{11}[x_1] + \cdots + c_{n1}x[n]] + \cdots + c_n[c_{1n}[x_1] + \cdots + c_{nn}x[n]]) \\
%         &\quad \mapsto
%         (c_1(c_{11}[x_1] + \cdots + c_{n1}x[n]) + \cdots + c_n(c_{1n}[x_1] + \cdots + c_{nn}x[n]))
%     \end{align*}
% \end{itemize}

% \subsection{Monads as spaces of generalized elements}
% The above description of probability monads give a hint towards 
% another way of understanding monads, which is to consider them 
% as a way to turn objects into ``generalized objects''~\citep{asilis2020probability} 
% and morphisms into ``generalized functions'':

% \begin{itemize}
%     \item The action on objects $X \mapsto TX$ sends an object $X$ to some ``generalized object''
%     $TX$;
%     \item The morphism $X \mor{f} Y$ gets sent to a ``generalized map'' 
%     $ TX \mor{Tf} TY$ that accepts a generalized input and returns a generalized output
%     \item The multiplication map $\mu : T T \Rightarrow T$ ``simplifies'' or ``evaluates''
%     a twice-generalized element to a generalized element. For this reason, it can 
%     be useful to think of $\mu$ as an \emph{evaluation map}. Naturality of evaluation 
%     corresponds to generalized maps commuting with evaluation.
% \end{itemize}

% % In the case of the distribution monad $\calD$, the generalized elements can be 
% % thought of as ``a weighted mixture of elements of a set'', and the evaluation map

% \section{Modeling effects with syntax}


% \section{Free algebras}
% Given a category $\calC$ and a monad $(T, \eta, \mu)$ on $\calC$

% \begin{definition}[Algebra]
%     An \emph{algebra} 
% \end{definition}

% \subsection{What's algebraic about free algebras?}
% \marginnote{In reference to \citep{bauer2018algebraic}}
% Above we motivated the Kleisli category 
